---
layout: post
title:  "理解 CPU Cache"
categories: Linux
---

下列两个循环哪个快？

~~~ c
int array[1024][1024]

// Loop 1
for(int i = 0; i < 1024; i ++)
    for(int j = 0; j < 1024; j ++)
        array[i][j] ++;

// Loop 2
for(int i = 0; i < 1024; i ++)
    for(int j = 0; j < 1024; j ++)
        array[j][i] ++;
~~~

Loop 1 的 CPU cache 命中率高，所以它比 Loop 2 约快八倍！

[Gallery of Processor Cache Effects](http://igoro.com/archive/gallery-of-processor-cache-effects/) 用 7 个源码示例生动的展示 cache，深入浅出！但是可能因操作系统的差异、编译器是否优化，以及近些年 cache 性能的提升，前 3 个样例在本人的 Macbook 中效果与原文相差较大。另外 Berkeley 公开课 [CS162](cs162.eecs.berkeley.edu) 图文并茂，非常推荐。本文充当搬运工的角色，集二者之精华科普 CPU cache 知识。 


----

# What is Cache

维基百科定义为：在计算机系统中，[CPU cache（中文简称缓存）](https://zh.wikipedia.org/wiki/CPU%E7%BC%93%E5%AD%98)是用于减少处理器访问内存所需平均时间的部件。在金字塔式存储体系中它位于自顶向下的第二层，仅次于 CPU 寄存器。其容量远小于内存，但速度却可以接近处理器的频率。

![hierarchy](http://7xp2eu.com1.z0.glb.clouddn.com/hierarchy%20cache.png)

*原图出处([CS162](cs162.eecs.berkeley.edu))。 Note: 早期的 L2 cache 位于主板，现在 L2 和 L3 cache 均封装于 CPU 芯片。*

CPU 访问内存时，首先查询 cache 是否已缓存该数据。如果有，则返回该数据，无需访问内存；如果不存在，则需把该数据从内存中载入 cache，最后返回给理器。在处理器看来，缓存是一个透明部件，旨在提高处理器访问数据的速率，所以从逻辑的角度而言，编程时无需关注它，但是从性能的角度而言，理解其原理和机制有助于写出性能更好的程序。Cache 之所以有效，是因为程序对内存的访问存在一种概率上的局部特征：

- Spatial Locality：对于刚被访问的数据，其相邻的数据在将来被访问的概率高。
- Temporal Locality：对于刚被访问的数据，其本身在将来被访问的概率高。

从广义的角度而言，cache 可以分为两类：

- 数据(指令) cache: 缓存内存数据，根据层级又可分为 L1、L2 和 L3，如果 miss，CPU 需访内存获取数据(指令)。 
- [TLB(Translation lookaside buffer)](https://en.wikipedia.org/wiki/Translation_lookaside_buffer): 寻址 cache，缓存进程虚拟机地址和物理地址的映射关系，如果 miss，MMU 需多次访问内存获取多级 page table 才能计算出物理地址。

比 Macbook 为例，可用 sysctl 查询 cache 信息。

~~~ bash
$ sysctl -a

hw.cachelinesize: 64
hw.l1icachesize: 32768
hw.l1dcachesize: 32768
hw.l2cachesize: 262144
hw.l3cachesize: 3145728
machdep.cpu.cache.L2_associativity: 8
machdep.cpu.core_count: 2
machdep.cpu.thread_count: 4
machdep.cpu.tlb.inst.large: 8
machdep.cpu.tlb.data.small: 64
machdep.cpu.tlb.data.small_level1: 64
machdep.cpu.tlb.shared: 1024
~~~

如下图：

![cpu cache](http://7xp2eu.com1.z0.glb.clouddn.com/mac_cpu_cache_info.png)

---

# Why Cache

早期的 CPU 并没有 cache，以起于 1978 年的 [intel x86](https://en.wikipedia.org/wiki/X86) 芯片为例，从 1992 年开始才开始引入 cache：

- 1992: 386 platform 引入 L1 cache
- 1995: Pentium Pro 引入 L2 cache
- 2008: Core i3 引入 L3 cache

CPU 和 RAM 主频的增长速率的巨大差距是 cache 引入的直接原因，下图展示了从 1980 年到 2000 年二者的发展状况，CPU 性能的年增长速度约为 60%，而 RAM 仅有约 9%，巨大的差异导致数十年后，CPU 的速度约比 RAM 快数百倍。 

![history](http://7xp2eu.com1.z0.glb.clouddn.com/Part6-CPU-and-RAM-speeds.jpg)

*原图出处: Computer Architecture, A quantitative Approach by Hennessy and Patterson*

有人问，为什么不提高 RAM 的速度，因为成本太高！成本因素也是 cache 分为多级的原因。越快的越贵，所以容量小；越慢越廉，容量可很大，它是成本和性能之间的折中方案。CS162 如下两句原话很好的概括了 cache 的作用。

- Present as much memory as in the cheapest technology
- Provide access at speed offered by the fastest technology

----

# Understand Cache With Some Cases

本节采用 [Gallery of Processor Cache Effects](http://igoro.com/archive/gallery-of-processor-cache-effects/) 的例子，加以图文，介绍 cache 的机制。

- Cache line size: cache line 是 cache 和 RAM 交换数据的最小单位，本小节介绍如何测算其大小。
- L1、L2 and L3 cache size
- Instruction-level parallelism: CPU 可在一定程度上并行处理。
- Cache associativity
- False cache line sharing
- Hardware complexities

## Cache line size

Cache line 是 cache 和 RAM 交换数据的最小单位，通常为 64 Byte。当 CPU 把内存的数据载入 cache 时，会把临近的共 64 Byte 的数据一起载入，因为临近的数据在将来被访问的可能性大，为 spatial locality 奠定了基础。本文开头的例子中，因为 loop 1 依次访问的数据在地址空间上是相邻的，故 cache 命中率高，耗时少。下列展示了如何测试 cache line 的 size:

~~~ c
double diff, total_time = 0;
struct timeval t1, t2;
char *array, *clear_array;

array = malloc(ARRAY_SIZE * sizeof(char));
clear_array = malloc(L3_SIZE * sizeof(char));

for(int t = 0; t < TIMES; t++)   //loop for many times
{
    gettimeofday(&t1, NULL);
    for(int i = 0; i < ARRAY_SIZE; i += stride){
        array[i]++;
    }
    gettimeofday(&t2, NULL);
    diff = time_diff(t1, t2);
    total_time += diff;

    //clear array data in L1,L2,L3 cache
    for(int i = 0; i < L3_SIZE; i ++){
        clear_array[i] ++;
    }
}
~~~

经归一化处理后，本人所测 array[i] ++ 的平均时间与 stride 的关系如下(如果关闭 hardware prefetch，效果可能会更好)：

![cpu cache line size](http://7xp2eu.com1.z0.glb.clouddn.com/cache_line_size.png)

## L1、L2 and L3 cache size

L1, L2 和 L3 cache size 的测试方法如下：

~~~
int steps = 64 * 1024 * 1024; // Arbitrary number of steps
int lengthMod = arr.Length - 1;
for (int i = 0; i < steps; i++)
{
    arr[(i * 16) & lengthMod]++; // (x & lengthMod) is equal to (x % arr.Length)
}
~~~

## Instruction-level parallelism

下列循环哪个快？

~~~ c
# Loop 1
gettimeofday(&t1, NULL);
for(int i = 0; i < ARRAY_SIZE - 1; i++){
    array[0] ++;
    array[0] ++;
}

# Loop 2
gettimeofday(&t2, NULL);
for(int i = 0; i < ARRAY_SIZE - 1; i++){
    array[0] ++;
    array[1] ++;
}

gettimeofday(&t3, NULL);

loop1_time = time_diff(t1, t2);
loop2_time = time_diff(t2, t3);
~~~

Loop 2 的速度比 Loop 1 接近快一倍。

目前 CPU 可以实现一定程度上的并行，比如在同一个时间点访问 L1 Cache 上的两处数据，也可以在同一个时间点执行两条算术运算指令。对于 Loop 2，它并行的运行 array[0] ++ 和 array[1] ++。

Loop 1

![cpu cache loop1](http://7xp2eu.com1.z0.glb.clouddn.com/cpu_cache_para_1.png)

Loop 2

![cpu cache loop1](http://7xp2eu.com1.z0.glb.clouddn.com/cpu_cache_para_2.png)


## Cache associativity


## False cache line sharing

以本人 Mac 的 CPU(Intel(R) Core(TM) i5-4258U CPU @ 2.40GHz) 为例，同一个 core 里的两个 cpu thread 共享 L1 和 L2 cache，L3 cache 则是由 2 个 core 共享。但一个 cpu thread 修改 cache 的某处时，该处所在的整个 cache line 都会被置为 invalid，其它的 cpu thread 不能使用该 cache line，直到数据被同步到 RAM 中。

~~~ c
int counter[1024]; // global variable

void *update_counter(int position)
{
    for(int i = 0; i < 1000000000; i ++ ){
        counter[position] ++;
    }

}

int main()
{
    double diff;
    struct timeval t1, t2;
    pthread_t tid1, tid2, tid3, tid4;

    // Sharing
    gettimeofday(&t1, NULL);
    pthread_create(&tid1, NULL, update_counter, (void *)1);
    pthread_create(&tid2, NULL, update_counter, (void *)2);
    pthread_create(&tid3, NULL, update_counter, (void *)3);
    pthread_create(&tid4, NULL, update_counter, (void *)4);

    pthread_join(tid1, NULL);
    pthread_join(tid2, NULL);
    pthread_join(tid3, NULL);
    pthread_join(tid4, NULL);
    gettimeofday(&t2, NULL);
    diff = time_diff(t1, t2);
    printf("%f\n", diff);

    // False Sharing
    gettimeofday(&t1, NULL);
    pthread_create(&tid1, NULL, update_counter, (void *)16);
    pthread_create(&tid2, NULL, update_counter, (void *)32);
    pthread_create(&tid3, NULL, update_counter, (void *)48);
    pthread_create(&tid4, NULL, update_counter, (void *)64);

    pthread_join(tid1, NULL);
    pthread_join(tid2, NULL);
    pthread_join(tid3, NULL);
    pthread_join(tid4, NULL);

    gettimeofday(&t2, NULL);
    diff = time_diff(t1, t2);
    printf("%f\n", diff);
}
~~~ 

并行创建 4 个线程执行上述函数，当 position 值分别为 1，2，3，4 时，所用总时间为 13.1 s，当值为 16，32，48，64 时，所用总时间为 3.4 s。

## Hardware complexities

上述例子为我们介绍了 Cache 的基本原理，但是 CPU 还是非常复杂多样。例如：

~~~ c
int A, B, C, D, E, F, G;

for (int i = 0; i < 200000000; i++)
{
    <something> // do something
}
~~~

结果为：

~~~ bash
<something>	           Time

A++; B++; C++; D++;	   719 ms
A++; C++; E++; G++;	   448 ms
A++; C++;	           518 ms
~~~



